{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ingridguza3103/Automating-SE/blob/main/Automation_AI_(3)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61dK1LuwUkGX",
    "outputId": "197001db-b2a5-4ee7-b346-f09dd572463e"
   },
   "outputs": [],
   "source": [
    "# ============================ 1. Setup ======================================\n",
    "!pip -q install \\\n",
    "    \"transformers==4.40.2\" \\\n",
    "    \"peft==0.5.0\" \\\n",
    "    \"datasets==2.18.0\" \\\n",
    "    \"evaluate==0.4.1\" \\\n",
    "    \"accelerate\" \\\n",
    "    \"scikit-learn\" -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZQgRpKGUPaK",
    "outputId": "7c28f8a4-3f60-4474-ee1e-52432c603c9f"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request, zipfile, json, os, random, torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import Dataset , load_metric\n",
    "import evaluate\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer,\n",
    "                          DataCollatorWithPadding)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61kZgvJzUhb7",
    "outputId": "5fcdf863-5426-45fc-af9a-0232ab6ff423"
   },
   "outputs": [],
   "source": [
    "# ============================ 2. Download Big-Vul ============================\n",
    "zip_url = \"https://raw.githubusercontent.com/Meerschwein/Automating-SE/refs/heads/main/Big-Vul-dataset.zip\"\n",
    "zip_path = Path(\"Big-Vul-dataset.zip\")\n",
    "data_dir = Path(\"Big-Vul-dataset\")\n",
    "\n",
    "if not zip_path.exists():\n",
    "    print(\"Downloading Big-Vul …\")\n",
    "    urllib.request.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "if not data_dir.exists():\n",
    "    print(\"Unpacking …\")\n",
    "    with zipfile.ZipFile(zip_path) as z: z.extractall(\"Big-Vul-dataset\")\n",
    "\n",
    "json_path = data_dir / \"data.json\"            # <- original file name\n",
    "assert json_path.exists(), \"data.json not found in the ZIP!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CJhBTwlUuKM",
    "outputId": "77839b1c-97a7-471d-f391-20a97b2219f6"
   },
   "outputs": [],
   "source": [
    "# ============================ 3. Load & light-clean ==========================\n",
    "print(\"Loading JSON …\")\n",
    "\n",
    "# --- 1)  Robustly read data.json  ------------------------------------------\n",
    "# Big-Vul dumps appear in **two** formats:\n",
    "#   • ordinary JSON array:     [ { … }, { … }, … ]\n",
    "#   • ND-JSON / JSONL:         { … }\\n{ … }\\n…\n",
    "# We’ll try ND-JSON first, then fall back automatically.\n",
    "\n",
    "try:                                # ➊ first try ND-JSON\n",
    "    df = pd.read_json(json_path, lines=True)\n",
    "except ValueError:                  # ➋ fall back to ordinary JSON array\n",
    "    df = pd.read_json(json_path)\n",
    "\n",
    "# If both attempts fail, go fully manual (extremely rare)\n",
    "if df.empty:\n",
    "    raw = json_path.read_text(encoding=\"utf-8\").strip()\n",
    "    if raw.startswith('['):                              # array\n",
    "        records = json.loads(raw)\n",
    "    else:                                                # ND-JSON\n",
    "        records = [json.loads(l) for l in raw.splitlines() if l.strip()]\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "print(\"Columns in data.json:\", list(df.columns))\n",
    "\n",
    "# --- 2)  Harmonise column names --------------------------------------------\n",
    "label_col_candidates = [\"target\", \"targets\", \"label\", \"vul\", \"vulnerable\"]\n",
    "for cand in label_col_candidates:\n",
    "    if cand in df.columns:\n",
    "        df = df.rename(columns={cand: \"label\"})\n",
    "        break\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"❌ Could not find a label column!\\nAvailable columns: %s\" % list(df.columns)\n",
    "    )\n",
    "\n",
    "if \"code\" not in df.columns:\n",
    "    if \"func\" in df.columns:\n",
    "        df = df.rename(columns={\"func\": \"code\"})\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"❌ Could not find a code column!\\nAvailable columns: %s\" % list(df.columns)\n",
    "        )\n",
    "\n",
    "# --- 3)  Keep only what we need & light cleaning ---------------------------\n",
    "df = df[[\"code\", \"label\"]].dropna()            # remove NaNs just in case\n",
    "df[\"label\"] = df[\"label\"].astype(int)          # ensure 0/1 ints\n",
    "\n",
    "# drop duplicate functions and over-long blobs (optional but helpful)\n",
    "df = df.drop_duplicates(\"code\")\n",
    "df = df[df.code.str.count(r\"\\n\") < 300].reset_index(drop=True)\n",
    "\n",
    "# --- 4)  Show class balance -------------------------------------------------\n",
    "print(\"\\nClass distribution (0 = benign, 1 = vulnerable):\")\n",
    "print(df.label.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKFSunvvUzfE"
   },
   "outputs": [],
   "source": [
    "# ============================ 4. Train / Val / Test split ====================\n",
    "train_df, test_df = train_test_split(df, test_size=0.15,\n",
    "                                     stratify=df.label, random_state=seed)\n",
    "train_df, val_df  = train_test_split(train_df, test_size=0.1,\n",
    "                                     stratify=train_df.label, random_state=seed)\n",
    "\n",
    "def to_hf(ds):\n",
    "    return Dataset.from_pandas(ds, preserve_index=False)\n",
    "\n",
    "train_ds, val_ds, test_ds = map(to_hf, (train_df, val_df, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "1f4bee9ffc8b4eaf9b7f427d23442519",
      "68749370694e4c99829e848339c9024a",
      "024d153ec1da4e0ea74806055090a8e1",
      "f45ffc16e2164c1abe56aa8607479c8f",
      "85e5b1ef365a4200a2092bdf9b00382c",
      "08bb6f59679b47388b00accfe73e14f0",
      "e0fc62f2c1a2420fa362c4e814e02bc5",
      "f05650e3e69b45268f6cf1c159ce967b",
      "4777ef3aff0049bbafe89370283461a5",
      "ba357ce40a6941b6a0199a6104841b6a",
      "82fefdb027e1450fb8db7d6a167925ae",
      "dc4391d02a2b4ca1bc8af5660d08fe26",
      "161bcb0cb7864e559bd4f6d738378d2c",
      "936ed3a17e6d4906897415039f7ab069",
      "f6449f5b56e6433a9c162f4d6a5b969e",
      "4821759989e84072898c1e5aeb05e5ea",
      "8aba24531422402b9eb1be4274a55d0e",
      "b69ae17ed26b47b4b80bfd5075b2be4a",
      "1f03b4a5366b4f3185f9f292afda6578",
      "8b9c564df5674509ad939fbb2d6a98d3",
      "8af53652441848db81ba21c91100abbb",
      "b3b61c8efa29442dbb196b3dfb16cd1e",
      "8c4c811713954b1bb54be25dace1c299",
      "137e3c43c78248b486dee154fdac4fd1",
      "495ae2540ea74f1abd24a6cf7930820b",
      "94cca49826204b33a79454e05bad8fa5",
      "f547b06739d94a008d8555b73237b7e5",
      "941b9d8067c84435a5c14f9cbe6be14e",
      "63dc1ff4fe0749d2addf0b15e1faab03",
      "90c27eac7a0c4b619bd81ff10aa12f0b",
      "40e7c57c489f41b294939f560b762ef7",
      "8f672b6253f64dd4b31c175a599c510f",
      "f9a3b96dec804b0996be2e4d9635e8b1",
      "64fa1b3fb40942d08b307e3ff0faab93",
      "e1ffdf5a46064995ac391802876175e3",
      "34a7b198f819443d9f549f062e20727c",
      "694d4dc131e0476f9e8e914163aebb8d",
      "39f4f5a902ed41219b619b2f6dafb102",
      "13f921186b654f698bc2464ae460fe70",
      "c92b757dd3904f9484d45d91637a388b",
      "9c34c0f646244ef6935a49e24d143622",
      "ac6ad7bc352e487b99a5b89f5b045678",
      "36f236ebaa754e90b1daabcbb515f082",
      "7e80156fbfab41da97a7e90252120c24",
      "8eb0231d49ea4016832bd36285e7d2da",
      "c0622d760276431db8a79f8a98f754ec",
      "519bb1a7690541d2844f81a281c4f61f",
      "c4aea4619998417f88ee2ec3121cd35b",
      "d199bb5f25624526b3f255c3b0117f14",
      "8e7a791564fd46618516a1dc71200288",
      "0cc50f7aa45d40cb871d0c83c4cb8873",
      "8dad00bd1e4b4942a1c5f25de120c5d0",
      "6b8d5d641ad64641a350f1a75c21aab3",
      "404d04ec7e29464c9a63de0fd20d8e4f",
      "82fa0c21f7014b449011fac0b9d37722",
      "51cc0ba2150641aaa84cace1eda478d2",
      "9b2ce6ccf91c4b199781a9849f6c109c",
      "683da2e48f124d7a8e72d2331ad273f9",
      "7d35f8a94f6a4b888853ebfa0ce4e77d",
      "ef539aa05de94767b0f39fa905bcbcef",
      "92b33ab715be45698f2257eda789f730",
      "e18c00f8f6a94667ab8935a19495cf69",
      "fda4dd96593747429b4026f134e09b6c",
      "9c106add6789401898a1c2380f96ba7e",
      "1a0cff5deaa64f508a50751454d638c0",
      "515e04e2c3ed4a6b9c4a3874b5a82616",
      "2320fed5982d4459bfd6372e008131e2",
      "4f84845ec3684fc9b14eedd954651196",
      "f6ce6941e1ef49118f4dc4d32ef25261",
      "32fd476ed8ed4db18e5c809f1b25dd18",
      "48a3e4085f0944e1a30976b4b67e383c",
      "941179b9eab74406800e10b4416c7441",
      "3b53b6980e12497bbd804a31cffef8e7",
      "0a57232fb0424d01bf752bb7417052f3",
      "a7f1ce4a7170409b94c4706fe3a1e3cf",
      "a88364d28a704a1e9501292023c39908",
      "a7d962aa87ce41febd61953e1d35e73f",
      "1ca3dcc2bccb463d8a1279c9b39e3d89",
      "1421bd8bc19d4b229662588503af4b7f",
      "b350fb14d2b6487885a7d2bac6414c95",
      "922f9613cb18431aa7aa1629439fd99e",
      "f491bbdfe7fc479fa5df0d454d7ec7fb",
      "9376c5487e5944e3addfc1efd419cc11",
      "a1695db76e964b58a490a4d537989146",
      "56e45fcbda654a45bc30b6feebb952f5",
      "22aae4e5db284e269aa85fb4c261b855",
      "efeee70912014daabe2eebc98f68eadf",
      "1719008afa0c474ea34e5b51c0d4c324"
     ]
    },
    "id": "9CxuWAhNU5Ox",
    "outputId": "e05ba6d8-8115-40d7-f03e-1f46066f92ad"
   },
   "outputs": [],
   "source": [
    "# ============================ 5. Tokenisation ===============================\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"code\"],\n",
    "               truncation=True,\n",
    "               max_length=512,\n",
    "               padding=\"max_length\")\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True, remove_columns=[\"code\"])\n",
    "val_ds   = val_ds.map(tokenize,   batched=True, remove_columns=[\"code\"])\n",
    "test_ds  = test_ds.map(tokenize,  batched=True, remove_columns=[\"code\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "6da223bbe8f44d9d91ddf781fe174ff0",
      "10114c011ff144b9b563871a7823a157",
      "30be7453cce24052a2934f7662f09bf8",
      "b13a883c46b44f89abcbe5be60806f3d",
      "a04201e0352d45f2b84281c5b07fe4f7",
      "ae43c0f123684c2c9d9a614ff440354c",
      "17865b80f47241d5b9ea1e43d199aded",
      "a644714efd644c3980d80cbceb88b9c5",
      "4fc5320e685c486cbcc2d208d5c120a1",
      "e49119974e2b422daf46f781e9bd11cf",
      "1300bf777f3b442c8116c7443275b62b"
     ]
    },
    "id": "gUcTco6GVNyE",
    "outputId": "580236cc-3a93-49b5-921e-f4e7020b9e27"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================ 6. Model ======================================\n",
    "# We keep all CodeBERT weights and only add the sequence-classification head\n",
    "# (a single linear layer that outputs 2 logits → benign / vulnerable).\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/codebert-base\", num_labels=2\n",
    ")\n",
    "\n",
    "#for p in model.base_model.parameters():      # \".roberta\" if using MiniLM etc.\n",
    "#    p.requires_grad = False\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Class-imbalance weights forwarded to Trainer\n",
    "# ---------------------------------------------------------------------------\n",
    "neg, pos = train_df.label.value_counts().sort_index().values\n",
    "class_weights = torch.tensor([1.0, neg / pos], dtype=torch.float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE6pwCcUVNtl"
   },
   "outputs": [],
   "source": [
    "# ============================ 7. Trainer setup ==============================\n",
    "class WeightedTrainer(Trainer):\n",
    "    \"\"\"Trainer that uses class-balanced CrossEntropyLoss.\"\"\"\n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights.to(self.model.device)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# --- metrics ---------------------------------------------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", zero_division=0, pos_label=1\n",
    "    )\n",
    "\n",
    "    acc = accuracy_score(labels, preds)            # ❷  accuracy\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    seed=seed,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tok,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights          # <-- passed to our subclass\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "NZzvsV5vVNqz",
    "outputId": "1a042c92-4a45-4507-fd0a-cf691d0f2fe6"
   },
   "outputs": [],
   "source": [
    "# ============================ 8. Training ====================================\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "6sZTWY3hVNmE",
    "outputId": "266d9e75-e6b8-40b3-c086-336c12d96130"
   },
   "outputs": [],
   "source": [
    "# ============================ 9. Final evaluation ============================\n",
    "print(\"\\n=== Test set metrics ===\")\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "for k,v in metrics.items():\n",
    "    if k.startswith(\"eval_\"): print(f\"{k[5:]} : {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QU5oQvv3VNbk",
    "outputId": "f5ebea3a-9cf3-4dfe-dda7-248c37053530"
   },
   "outputs": [],
   "source": [
    "# ============================ 10. Save model ================================\n",
    "trainer.save_model(\"codebert-bigvul-func\")\n",
    "tok.save_pretrained(\"codebert-bigvul-func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf31j5qfVNKl",
    "outputId": "72b12bc2-18bc-4e81-b8ce-e0f8a10b34fd"
   },
   "outputs": [],
   "source": [
    "# ============================ 11. Inspect sample predictions ===============\n",
    "import textwrap, torch, random\n",
    "\n",
    "k = 5                                          # number of samples to display\n",
    "sample_rows = test_df.sample(k, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "model.eval()                                   # just in case\n",
    "for i, row in sample_rows.iterrows():\n",
    "    code_snippet = row[\"code\"]\n",
    "    true_label   = int(row[\"label\"])\n",
    "\n",
    "    # tokenize + forward pass\n",
    "    inputs = tok(code_snippet,\n",
    "                 return_tensors=\"pt\",\n",
    "                 truncation=True,\n",
    "                 max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    prob = torch.softmax(logits, dim=-1)[0, 1].item()\n",
    "    pred = int(prob > 0.5)\n",
    "\n",
    "    # pretty print\n",
    "    print(\"=\"*80)\n",
    "    print(f\"SAMPLE {i+1}\")\n",
    "    print(f\"Ground-truth:  {'VULNERABLE' if true_label else 'BENIGN'}\")\n",
    "    print(f\"Model pred.:  {'VULNERABLE' if pred       else 'BENIGN'}  \"\n",
    "          f\"(prob = {prob:.2f})\")\n",
    "    print(\"-\"*80)\n",
    "    # show first 40 lines (or the whole thing if it's shorter)\n",
    "    lines = code_snippet.splitlines()\n",
    "    if len(lines) > 40:\n",
    "        lines = lines[:40] + [\"    … (truncated) …\"]\n",
    "    print(\"\\n\".join(f\"{j+1:>3}: {line}\" for j, line in enumerate(lines)))\n",
    "    print()  # blank line between samples"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}